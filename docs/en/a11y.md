# Accessibility (a11y)
gShell is designed from the ground up to accommodate all users and allow them to navigate and use their devices through ways that suit their individual needs. The needs of a user may be dependent on their abilities, such as whether they have a visual or auditory impairment, or if they do not have fine motor skills. Our goal is to build a platform that is easily usable and _accessible_ to everyone, regardless of their abilities and disabilities.

**Assistive technologies** (ATs) are software and/or hardware systems that make interacting with a device convenient for a user with certain needs. Without certain ATs, it can become impossible for some users to perform certain tasks, making a system inaccessible and practically unusable for the user. It is important that gShell implements the relevant software ATs and is designed to communicate with the relevant hardware ATs for this reason.

Some examples of software assistive technologies include:

* A **screen reader** for blind or visually impaired users that allows users to interpret information via speech synthesis or refreshable Braille displays instead of a graphical display
* **Subtitle rendering** for deaf or hard-of-hearing users that allows users to watch videos and understand spoken elements or sound effects without audio
* The **sticky keys** keyboard configuration for users with limited motor skills or who cannot make use of two hands, allowing them to enter keyboard shortcuts and perform other multi-key actions without having to hold down multiple keys at once

Some examples of hardware assistive technologies include:

* **Switches** for users with limited motor skills — a switch is an input device that often resembles a single, large button and can be mounted in locations that make it easy to activate by the user, often to control a device using at least one switch
* **Hearing aids** for deaf or hard-of-hearing users that amplify sound so it can be more easily heard by the user — more modern models can connect to devices via Bluetooth for a clean, direct transmission of audio

Users without any specific impairments may still make use of assistive technologies to make using their device easier; for example, when a user is watching a video in a loud environment such as public transport, they can enable subtitles to help them better understand spoken elements in the video.

gShell hopes to implement as many ATs as possible to make using gShell convenient for everyone. Implementations are included in the `shell/a11y` directory, and all implemented ATs inherit the `AssistiveTechnology` class found in `a11y.js`.

## AT implementations

### Switch Navigation (`switch.js`)
This AT is designed to interact with accessible switches to enable users to use gShell using at least one switch.

There are many types of switches (which include push-button switches, foot pedal switches, sip-and-puff switches and more), but a large number of switches make use of a simple, 3.5 mm mono audio jack for communications. When a switch is activated, the circuit made by the audio jack either opens or closes (depending on the type of switch). Switches are designed to plug into a switch interface device that converts activations into keyboard events and sends those events down a USB or Bluetooth connection. A device, such as one running gShell, can then interpret the keyboard events and act accordingly.

Since switches are typically (and rather strangely) expensive devices, for testing, you can use a simple USB or Bluetooth keyboard and set that up for use with gShell's Switch Navigation feature. We also plan to allow users to map the volume buttons on their devices (and potentially also the whole touchscreen, if present) to switch inputs for testing purposes, too.

Switch Navigation makes use of two different modes to allow for the interaction of on-screen elements, and these modes are easily interchangable by the user to deal with different scenarios:

* **Item scanning mode**: Each user interface element is highlighted one-at-a-time, and the user can either wait or repeatedly press a switch until the appropriate item is selected. The user can then press a switch to select the item.
* **Point scanning mode**: The user chooses a point on-screen to click on via a pair of crosshairs that move horizontally until a switch is pressed, then vertically until the switch is pressed again. The point intersected by the two axis is then clicked on. Some implementations make use of a refinement option whereby a coarse target location is chosen, then refined using a slower moving axis, which is something that we should implement, too.

We can make use of the `"io_input"` IPC call to emit virtual events for the keyboard (for item scanning mode, which makes use of the <kbd>Tab</kbd> key) and the mouse (for point scanning mode).

#### Testing Switch Navigation
Currently, the easiest way to try out Switch Navigation in gShell for development purposes is to use the `--enable-a11y-switch` flag when starting gShell from the terminal. You can then press the <kbd>Space</kbd> key to select items when they are focused.

Switch Navigation can also be turned on within gShell itself by visiting **Settings** > **Accessibility** > **Switch Navigaton** > **Enable Switch Navigation**.